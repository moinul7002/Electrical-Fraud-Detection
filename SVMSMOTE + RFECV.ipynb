{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3523d519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbd78317",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "#from catboost import CatBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "#import lightgbm as lgb\n",
    "#from lightgbm import LGBMClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import interp\n",
    "from sklearn.metrics import classification_report, accuracy_score, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f842fb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"after_outlier_dataset.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc5677d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disrict</th>\n",
       "      <th>client_catg</th>\n",
       "      <th>region</th>\n",
       "      <th>region_group</th>\n",
       "      <th>coop_time</th>\n",
       "      <th>is_weekday_mean</th>\n",
       "      <th>transactions_count</th>\n",
       "      <th>tarif_type_mean</th>\n",
       "      <th>tarif_type_std</th>\n",
       "      <th>tarif_type_min</th>\n",
       "      <th>...</th>\n",
       "      <th>months_number_max_mean</th>\n",
       "      <th>counter_type_range</th>\n",
       "      <th>counter_type_max_mean</th>\n",
       "      <th>invoice_month_range</th>\n",
       "      <th>invoice_month_max_mean</th>\n",
       "      <th>invoice_year_range</th>\n",
       "      <th>invoice_year_max_mean</th>\n",
       "      <th>delta_index_range</th>\n",
       "      <th>delta_index_max_mean</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.582524</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.073394</td>\n",
       "      <td>0.040251</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.227106</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.721412</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>0.788090</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.409709</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.077982</td>\n",
       "      <td>0.040251</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009348</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.270677</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.657374</td>\n",
       "      <td>0.000899</td>\n",
       "      <td>0.788028</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.671141</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.786408</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.034404</td>\n",
       "      <td>0.040251</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.189676</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.739702</td>\n",
       "      <td>0.002560</td>\n",
       "      <td>0.788085</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013423</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.537864</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.038991</td>\n",
       "      <td>0.040251</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.229086</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.312570</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.788415</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.677852</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.120388</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.025229</td>\n",
       "      <td>0.040251</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.167116</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.196191</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>0.788043</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123552</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.304854</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.073394</td>\n",
       "      <td>0.289597</td>\n",
       "      <td>0.700486</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010998</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.291209</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.354148</td>\n",
       "      <td>0.001358</td>\n",
       "      <td>0.788062</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123553</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.955340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002294</td>\n",
       "      <td>0.007318</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003666</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.204082</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.092051</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.788044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123554</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.704698</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166990</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087156</td>\n",
       "      <td>0.529420</td>\n",
       "      <td>0.747623</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.186636</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.290447</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.788113</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123555</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.704698</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.188350</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.075688</td>\n",
       "      <td>0.411657</td>\n",
       "      <td>0.730415</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010403</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.042424</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.211982</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.394622</td>\n",
       "      <td>0.000921</td>\n",
       "      <td>0.788094</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123556</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.788350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040251</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.787996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117340 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         disrict  client_catg    region  region_group  coop_time  \\\n",
       "0       0.000000          0.0  0.000000           0.0   0.582524   \n",
       "1       1.000000          0.0  0.020134           0.0   0.409709   \n",
       "2       0.222222          0.0  0.671141           1.0   0.786408   \n",
       "3       1.000000          0.0  0.013423           0.0   0.537864   \n",
       "4       0.222222          0.0  0.677852           1.0   0.120388   \n",
       "...          ...          ...       ...           ...        ...   \n",
       "123552  0.000000          0.0  0.000000           0.0   0.304854   \n",
       "123553  0.000000          0.0  0.000000           0.0   0.955340   \n",
       "123554  0.333333          0.0  0.704698           1.0   0.166990   \n",
       "123555  0.333333          0.0  0.704698           1.0   0.188350   \n",
       "123556  0.000000          0.0  0.000000           0.0   0.788350   \n",
       "\n",
       "        is_weekday_mean  transactions_count  tarif_type_mean  tarif_type_std  \\\n",
       "0              0.028571            0.073394         0.040251        0.000000   \n",
       "1              0.054054            0.077982         0.040251        0.000000   \n",
       "2              0.055556            0.034404         0.040251        0.000000   \n",
       "3              0.050000            0.038991         0.040251        0.000000   \n",
       "4              0.285714            0.025229         0.040251        0.000000   \n",
       "...                 ...                 ...              ...             ...   \n",
       "123552         0.200000            0.073394         0.289597        0.700486   \n",
       "123553         0.000000            0.002294         0.007318        0.000000   \n",
       "123554         0.000000            0.087156         0.529420        0.747623   \n",
       "123555         0.194444            0.075688         0.411657        0.730415   \n",
       "123556         0.000000            0.000000         0.040251        0.000000   \n",
       "\n",
       "        tarif_type_min  ...  months_number_max_mean  counter_type_range  \\\n",
       "0             0.142857  ...                0.017515                 0.0   \n",
       "1             0.142857  ...                0.009348                 0.0   \n",
       "2             0.142857  ...                0.009481                 0.0   \n",
       "3             0.142857  ...                0.004713                 0.0   \n",
       "4             0.142857  ...                0.000846                 0.0   \n",
       "...                ...  ...                     ...                 ...   \n",
       "123552        0.095238  ...                0.010998                 1.0   \n",
       "123553        0.095238  ...                0.003666                 0.0   \n",
       "123554        0.142857  ...                0.000275                 1.0   \n",
       "123555        0.142857  ...                0.010403                 1.0   \n",
       "123556        0.142857  ...                0.000000                 0.0   \n",
       "\n",
       "        counter_type_max_mean  invoice_month_range  invoice_month_max_mean  \\\n",
       "0                    0.000000             1.000000                0.227106   \n",
       "1                    0.000000             0.818182                0.270677   \n",
       "2                    0.000000             0.818182                0.189676   \n",
       "3                    0.000000             0.818182                0.229086   \n",
       "4                    0.000000             0.909091                0.167116   \n",
       "...                       ...                  ...                     ...   \n",
       "123552               0.026667             1.000000                0.291209   \n",
       "123553               0.000000             0.727273                0.204082   \n",
       "123554               0.070000             0.727273                0.186636   \n",
       "123555               0.042424             0.909091                0.211982   \n",
       "123556               0.000000             0.727273                0.228571   \n",
       "\n",
       "        invoice_year_range  invoice_year_max_mean  delta_index_range  \\\n",
       "0                 1.000000               0.721412           0.001192   \n",
       "1                 1.000000               0.657374           0.000899   \n",
       "2                 1.000000               0.739702           0.002560   \n",
       "3                 0.500000               0.312570           0.000012   \n",
       "4                 0.285714               0.196191           0.001997   \n",
       "...                    ...                    ...                ...   \n",
       "123552            0.642857               0.354148           0.001358   \n",
       "123553            0.142857               0.092051           0.000026   \n",
       "123554            0.428571               0.290447           0.000735   \n",
       "123555            0.500000               0.394622           0.000921   \n",
       "123556            0.000000               0.000000           0.000304   \n",
       "\n",
       "        delta_index_max_mean  target  \n",
       "0                   0.788090       0  \n",
       "1                   0.788028       0  \n",
       "2                   0.788085       0  \n",
       "3                   0.788415       0  \n",
       "4                   0.788043       0  \n",
       "...                      ...     ...  \n",
       "123552              0.788062       0  \n",
       "123553              0.788044       0  \n",
       "123554              0.788113       0  \n",
       "123555              0.788094       0  \n",
       "123556              0.787996       0  \n",
       "\n",
       "[117340 rows x 105 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e55d4242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Non-fraudalent Cases: 110575\n",
      "No. of Fraudalent Cases: 6765\n"
     ]
    }
   ],
   "source": [
    "not_fraud = df[(df['target'] == 0 )].count()[1]\n",
    "fraud = df[(df['target'] == 1 )].count()[1]\n",
    "print('No. of Non-fraudalent Cases: '+ str(not_fraud))\n",
    "print('No. of Fraudalent Cases: '+ str(fraud))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55e89bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size = 0.3, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af98ac72",
   "metadata": {},
   "source": [
    "## Borderline SMOTE with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01779da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import BorderlineSMOTE\n",
    "from imblearn.over_sampling import SVMSMOTE\n",
    "\n",
    "X_train_s, y_train_s = SVMSMOTE(random_state=42).fit_resample(X_train, y_train.ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "442da92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 77428), (1, 77428)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(sorted(Counter(y_train_s).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e6a9d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=100,random_state = 42)\n",
    "rfc.fit(X_train_s, y_train_s)\n",
    "rfc_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11978cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9402874836657008\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     33147\n",
      "           1       0.48      0.28      0.35      2055\n",
      "\n",
      "    accuracy                           0.94     35202\n",
      "   macro avg       0.72      0.63      0.66     35202\n",
      "weighted avg       0.93      0.94      0.93     35202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,rfc_pred))\n",
    "print(classification_report(y_test,rfc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3f30efdc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test_s' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-199999e7065d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mconf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrfc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test_s' is not defined"
     ]
    }
   ],
   "source": [
    "conf(rfc,X_test_s, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38aee79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9200045451962957\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96     33147\n",
      "           1       0.34      0.38      0.36      2055\n",
      "\n",
      "    accuracy                           0.92     35202\n",
      "   macro avg       0.65      0.67      0.66     35202\n",
      "weighted avg       0.92      0.92      0.92     35202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier()\n",
    "gbc.fit(X_train_s,y_train_s)\n",
    "predictions = gbc.predict(X_test)\n",
    "print(accuracy_score(y_test, predictions))\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f554b14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8387023464575877\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.86      0.91     33147\n",
      "           1       0.18      0.50      0.27      2055\n",
      "\n",
      "    accuracy                           0.84     35202\n",
      "   macro avg       0.57      0.68      0.59     35202\n",
      "weighted avg       0.92      0.84      0.87     35202\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moinu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logmodel = LogisticRegression()\n",
    "logmodel.fit(X_train_s,y_train_s)\n",
    "predictions = logmodel.predict(X_test)\n",
    "print(accuracy_score(y_test, predictions))\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57c5ea4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score KNeighnors : 0.8499801147662065\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.88      0.92     33147\n",
      "           1       0.17      0.39      0.23      2055\n",
      "\n",
      "    accuracy                           0.85     35202\n",
      "   macro avg       0.56      0.63      0.57     35202\n",
      "weighted avg       0.91      0.85      0.88     35202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knneig = KNeighborsClassifier(n_neighbors=10)\n",
    "knneig.fit(X_train_s, y_train_s)\n",
    "pred_knneigh = knneig.predict(X_test)\n",
    "score_knneigh_before = accuracy_score(y_test, pred_knneigh)\n",
    "print(\"Score KNeighnors :\",score_knneigh_before)\n",
    "print(classification_report(y_test, pred_knneigh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9aad33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moinu\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9419635247997273\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     33147\n",
      "           1       0.51      0.26      0.35      2055\n",
      "\n",
      "    accuracy                           0.94     35202\n",
      "   macro avg       0.73      0.62      0.66     35202\n",
      "weighted avg       0.93      0.94      0.93     35202\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moinu\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "xg = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42, eval_metric=\"auc\")\n",
    "xg.fit(X_train_s,y_train_s)\n",
    "predictions = xg.predict(X_test)\n",
    "print(accuracy_score(y_test, predictions))\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5aa57c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8898073973069712\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94     33147\n",
      "           1       0.24      0.40      0.30      2055\n",
      "\n",
      "    accuracy                           0.89     35202\n",
      "   macro avg       0.60      0.66      0.62     35202\n",
      "weighted avg       0.92      0.89      0.90     35202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ada = AdaBoostClassifier()\n",
    "ada.fit(X_train_s,y_train_s)\n",
    "predictions = ada.predict(X_test)\n",
    "print(accuracy_score(y_test, predictions))\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "168eb9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "model= tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(units=64,activation='relu',input_shape= (104,)))\n",
    "model.add(tf.keras.layers.Dense(units=128,activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(units=1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad2c6b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 64)                6720      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 15,169\n",
      "Trainable params: 15,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d4a1b977",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "7743/7743 [==============================] - 7s 893us/step - loss: 0.1721 - accuracy: 0.9350\n",
      "Epoch 2/150\n",
      "7743/7743 [==============================] - 7s 894us/step - loss: 0.1711 - accuracy: 0.9350\n",
      "Epoch 3/150\n",
      "7743/7743 [==============================] - 7s 911us/step - loss: 0.1696 - accuracy: 0.9358\n",
      "Epoch 4/150\n",
      "7743/7743 [==============================] - 7s 908us/step - loss: 0.1690 - accuracy: 0.9359\n",
      "Epoch 5/150\n",
      "7743/7743 [==============================] - 7s 910us/step - loss: 0.1677 - accuracy: 0.9365\n",
      "Epoch 6/150\n",
      "7743/7743 [==============================] - 7s 905us/step - loss: 0.1672 - accuracy: 0.9368\n",
      "Epoch 7/150\n",
      "7743/7743 [==============================] - 7s 963us/step - loss: 0.1659 - accuracy: 0.9376\n",
      "Epoch 8/150\n",
      "7743/7743 [==============================] - 8s 999us/step - loss: 0.1647 - accuracy: 0.9378\n",
      "Epoch 9/150\n",
      "7743/7743 [==============================] - 7s 958us/step - loss: 0.1646 - accuracy: 0.9377\n",
      "Epoch 10/150\n",
      "7743/7743 [==============================] - 7s 952us/step - loss: 0.1641 - accuracy: 0.9384\n",
      "Epoch 11/150\n",
      "7743/7743 [==============================] - 7s 941us/step - loss: 0.1626 - accuracy: 0.9392\n",
      "Epoch 12/150\n",
      "7743/7743 [==============================] - 7s 956us/step - loss: 0.1615 - accuracy: 0.9393\n",
      "Epoch 13/150\n",
      "7743/7743 [==============================] - 7s 947us/step - loss: 0.1610 - accuracy: 0.9395\n",
      "Epoch 14/150\n",
      "7743/7743 [==============================] - 7s 943us/step - loss: 0.1599 - accuracy: 0.9404\n",
      "Epoch 15/150\n",
      "7743/7743 [==============================] - 7s 962us/step - loss: 0.1601 - accuracy: 0.9399\n",
      "Epoch 16/150\n",
      "7743/7743 [==============================] - 7s 961us/step - loss: 0.1593 - accuracy: 0.9402\n",
      "Epoch 17/150\n",
      "7743/7743 [==============================] - 7s 954us/step - loss: 0.1583 - accuracy: 0.9406\n",
      "Epoch 18/150\n",
      "7743/7743 [==============================] - 7s 963us/step - loss: 0.1572 - accuracy: 0.9408\n",
      "Epoch 19/150\n",
      "7743/7743 [==============================] - 7s 950us/step - loss: 0.1564 - accuracy: 0.9414\n",
      "Epoch 20/150\n",
      "7743/7743 [==============================] - 7s 960us/step - loss: 0.1559 - accuracy: 0.9416\n",
      "Epoch 21/150\n",
      "7743/7743 [==============================] - 7s 958us/step - loss: 0.1556 - accuracy: 0.9426\n",
      "Epoch 22/150\n",
      "7743/7743 [==============================] - 7s 950us/step - loss: 0.1549 - accuracy: 0.9420\n",
      "Epoch 23/150\n",
      "7743/7743 [==============================] - 7s 951us/step - loss: 0.1542 - accuracy: 0.9426\n",
      "Epoch 24/150\n",
      "7743/7743 [==============================] - 7s 959us/step - loss: 0.1540 - accuracy: 0.9429\n",
      "Epoch 25/150\n",
      "7743/7743 [==============================] - 7s 955us/step - loss: 0.1523 - accuracy: 0.9433\n",
      "Epoch 26/150\n",
      "7743/7743 [==============================] - 7s 946us/step - loss: 0.1526 - accuracy: 0.9429\n",
      "Epoch 27/150\n",
      "7743/7743 [==============================] - 7s 945us/step - loss: 0.1519 - accuracy: 0.9433\n",
      "Epoch 28/150\n",
      "7743/7743 [==============================] - 7s 953us/step - loss: 0.1515 - accuracy: 0.9443\n",
      "Epoch 29/150\n",
      "7743/7743 [==============================] - 7s 953us/step - loss: 0.1504 - accuracy: 0.9442\n",
      "Epoch 30/150\n",
      "7743/7743 [==============================] - 7s 951us/step - loss: 0.1499 - accuracy: 0.9442\n",
      "Epoch 31/150\n",
      "7743/7743 [==============================] - 7s 957us/step - loss: 0.1492 - accuracy: 0.9450\n",
      "Epoch 32/150\n",
      "7743/7743 [==============================] - 7s 956us/step - loss: 0.1484 - accuracy: 0.9455\n",
      "Epoch 33/150\n",
      "7743/7743 [==============================] - 7s 956us/step - loss: 0.1482 - accuracy: 0.9445\n",
      "Epoch 34/150\n",
      "7743/7743 [==============================] - 7s 960us/step - loss: 0.1479 - accuracy: 0.9453\n",
      "Epoch 35/150\n",
      "7743/7743 [==============================] - 7s 961us/step - loss: 0.1471 - accuracy: 0.9453\n",
      "Epoch 36/150\n",
      "7743/7743 [==============================] - 7s 948us/step - loss: 0.1459 - accuracy: 0.9467\n",
      "Epoch 37/150\n",
      "7743/7743 [==============================] - 7s 949us/step - loss: 0.1460 - accuracy: 0.9463\n",
      "Epoch 38/150\n",
      "7743/7743 [==============================] - 7s 952us/step - loss: 0.1453 - accuracy: 0.9458\n",
      "Epoch 39/150\n",
      "7743/7743 [==============================] - 7s 955us/step - loss: 0.1442 - accuracy: 0.9470\n",
      "Epoch 40/150\n",
      "7743/7743 [==============================] - 7s 946us/step - loss: 0.1438 - accuracy: 0.9476\n",
      "Epoch 41/150\n",
      "7743/7743 [==============================] - 7s 949us/step - loss: 0.1432 - accuracy: 0.9473\n",
      "Epoch 42/150\n",
      "7743/7743 [==============================] - 7s 958us/step - loss: 0.1428 - accuracy: 0.9481\n",
      "Epoch 43/150\n",
      "7743/7743 [==============================] - 7s 957us/step - loss: 0.1425 - accuracy: 0.9473\n",
      "Epoch 44/150\n",
      "7743/7743 [==============================] - 7s 952us/step - loss: 0.1421 - accuracy: 0.9477\n",
      "Epoch 45/150\n",
      "7743/7743 [==============================] - 8s 974us/step - loss: 0.1414 - accuracy: 0.9478\n",
      "Epoch 46/150\n",
      "7743/7743 [==============================] - 8s 974us/step - loss: 0.1412 - accuracy: 0.9478\n",
      "Epoch 47/150\n",
      "7743/7743 [==============================] - 7s 951us/step - loss: 0.1411 - accuracy: 0.9479\n",
      "Epoch 48/150\n",
      "7743/7743 [==============================] - 7s 951us/step - loss: 0.1395 - accuracy: 0.9493\n",
      "Epoch 49/150\n",
      "7743/7743 [==============================] - 7s 956us/step - loss: 0.1395 - accuracy: 0.9486\n",
      "Epoch 50/150\n",
      "7743/7743 [==============================] - 7s 949us/step - loss: 0.1388 - accuracy: 0.9491\n",
      "Epoch 51/150\n",
      "7743/7743 [==============================] - 7s 959us/step - loss: 0.1392 - accuracy: 0.9492\n",
      "Epoch 52/150\n",
      "7743/7743 [==============================] - 7s 961us/step - loss: 0.1376 - accuracy: 0.9496\n",
      "Epoch 53/150\n",
      "7743/7743 [==============================] - 7s 953us/step - loss: 0.1383 - accuracy: 0.9494\n",
      "Epoch 54/150\n",
      "7743/7743 [==============================] - 7s 946us/step - loss: 0.1378 - accuracy: 0.9494\n",
      "Epoch 55/150\n",
      "7743/7743 [==============================] - 7s 955us/step - loss: 0.1371 - accuracy: 0.9499\n",
      "Epoch 56/150\n",
      "7743/7743 [==============================] - 7s 957us/step - loss: 0.1362 - accuracy: 0.9499\n",
      "Epoch 57/150\n",
      "7743/7743 [==============================] - 8s 1ms/step - loss: 0.1365 - accuracy: 0.9505\n",
      "Epoch 58/150\n",
      "7743/7743 [==============================] - 7s 967us/step - loss: 0.1360 - accuracy: 0.9499\n",
      "Epoch 59/150\n",
      "7743/7743 [==============================] - 7s 948us/step - loss: 0.1352 - accuracy: 0.9506\n",
      "Epoch 60/150\n",
      "7743/7743 [==============================] - 8s 1ms/step - loss: 0.1350 - accuracy: 0.9507\n",
      "Epoch 61/150\n",
      "7743/7743 [==============================] - 7s 961us/step - loss: 0.1344 - accuracy: 0.9507\n",
      "Epoch 62/150\n",
      "7743/7743 [==============================] - 7s 952us/step - loss: 0.1345 - accuracy: 0.9507\n",
      "Epoch 63/150\n",
      "7743/7743 [==============================] - 7s 958us/step - loss: 0.1339 - accuracy: 0.9512\n",
      "Epoch 64/150\n",
      "7743/7743 [==============================] - 7s 944us/step - loss: 0.1337 - accuracy: 0.9512\n",
      "Epoch 65/150\n",
      "7743/7743 [==============================] - 7s 945us/step - loss: 0.1327 - accuracy: 0.9516\n",
      "Epoch 66/150\n",
      "7743/7743 [==============================] - 7s 944us/step - loss: 0.1332 - accuracy: 0.9520\n",
      "Epoch 67/150\n",
      "7743/7743 [==============================] - 7s 952us/step - loss: 0.1325 - accuracy: 0.9518\n",
      "Epoch 68/150\n",
      "7743/7743 [==============================] - 7s 952us/step - loss: 0.1321 - accuracy: 0.9518\n",
      "Epoch 69/150\n",
      "7743/7743 [==============================] - 7s 956us/step - loss: 0.1315 - accuracy: 0.9521\n",
      "Epoch 70/150\n",
      "7743/7743 [==============================] - 7s 950us/step - loss: 0.1316 - accuracy: 0.9525\n",
      "Epoch 71/150\n",
      "7743/7743 [==============================] - 7s 954us/step - loss: 0.1310 - accuracy: 0.9520\n",
      "Epoch 72/150\n",
      "7743/7743 [==============================] - 7s 950us/step - loss: 0.1308 - accuracy: 0.9527\n",
      "Epoch 73/150\n",
      "7743/7743 [==============================] - 7s 942us/step - loss: 0.1302 - accuracy: 0.9533\n",
      "Epoch 74/150\n",
      "7743/7743 [==============================] - 7s 945us/step - loss: 0.1305 - accuracy: 0.9525\n",
      "Epoch 75/150\n",
      "7743/7743 [==============================] - 7s 944us/step - loss: 0.1303 - accuracy: 0.9527\n",
      "Epoch 76/150\n",
      "7743/7743 [==============================] - 7s 943us/step - loss: 0.1300 - accuracy: 0.9525\n",
      "Epoch 77/150\n",
      "7743/7743 [==============================] - 7s 939us/step - loss: 0.1292 - accuracy: 0.9533\n",
      "Epoch 78/150\n",
      "7743/7743 [==============================] - 7s 949us/step - loss: 0.1293 - accuracy: 0.9529\n",
      "Epoch 79/150\n",
      "7743/7743 [==============================] - 7s 938us/step - loss: 0.1287 - accuracy: 0.9529\n",
      "Epoch 80/150\n",
      "7743/7743 [==============================] - 7s 952us/step - loss: 0.1281 - accuracy: 0.9541\n",
      "Epoch 81/150\n",
      "7743/7743 [==============================] - 7s 944us/step - loss: 0.1282 - accuracy: 0.9534\n",
      "Epoch 82/150\n",
      "7743/7743 [==============================] - 7s 938us/step - loss: 0.1284 - accuracy: 0.9534\n",
      "Epoch 83/150\n",
      "7743/7743 [==============================] - 7s 948us/step - loss: 0.1273 - accuracy: 0.9537\n",
      "Epoch 84/150\n",
      "7743/7743 [==============================] - 7s 947us/step - loss: 0.1276 - accuracy: 0.9539\n",
      "Epoch 85/150\n",
      "7743/7743 [==============================] - 7s 946us/step - loss: 0.1265 - accuracy: 0.9549\n",
      "Epoch 86/150\n",
      "7743/7743 [==============================] - 7s 941us/step - loss: 0.1267 - accuracy: 0.9543\n",
      "Epoch 87/150\n",
      "7743/7743 [==============================] - 7s 958us/step - loss: 0.1261 - accuracy: 0.9552\n",
      "Epoch 88/150\n",
      "7743/7743 [==============================] - 7s 948us/step - loss: 0.1257 - accuracy: 0.9548\n",
      "Epoch 89/150\n",
      "7743/7743 [==============================] - 7s 947us/step - loss: 0.1258 - accuracy: 0.9546\n",
      "Epoch 90/150\n",
      "7743/7743 [==============================] - 7s 953us/step - loss: 0.1262 - accuracy: 0.9544\n",
      "Epoch 91/150\n",
      "7743/7743 [==============================] - 8s 1ms/step - loss: 0.1253 - accuracy: 0.9546\n",
      "Epoch 92/150\n",
      "7743/7743 [==============================] - 7s 938us/step - loss: 0.1249 - accuracy: 0.9546\n",
      "Epoch 93/150\n",
      "7743/7743 [==============================] - 7s 940us/step - loss: 0.1247 - accuracy: 0.9551\n",
      "Epoch 94/150\n",
      "7743/7743 [==============================] - 7s 934us/step - loss: 0.1249 - accuracy: 0.9550\n",
      "Epoch 95/150\n",
      "7743/7743 [==============================] - 7s 932us/step - loss: 0.1247 - accuracy: 0.9550\n",
      "Epoch 96/150\n",
      "7743/7743 [==============================] - 7s 942us/step - loss: 0.1236 - accuracy: 0.9556\n",
      "Epoch 97/150\n",
      "7743/7743 [==============================] - 8s 1ms/step - loss: 0.1239 - accuracy: 0.9556\n",
      "Epoch 98/150\n",
      "7743/7743 [==============================] - 8s 971us/step - loss: 0.1235 - accuracy: 0.9558\n",
      "Epoch 99/150\n",
      "7743/7743 [==============================] - 7s 944us/step - loss: 0.1230 - accuracy: 0.9554\n",
      "Epoch 100/150\n",
      "7743/7743 [==============================] - 7s 950us/step - loss: 0.1238 - accuracy: 0.9557\n",
      "Epoch 101/150\n",
      "7743/7743 [==============================] - 7s 948us/step - loss: 0.1220 - accuracy: 0.9558\n",
      "Epoch 102/150\n",
      "7743/7743 [==============================] - 7s 950us/step - loss: 0.1227 - accuracy: 0.9562\n",
      "Epoch 103/150\n",
      "7743/7743 [==============================] - 7s 949us/step - loss: 0.1224 - accuracy: 0.9560\n",
      "Epoch 104/150\n",
      "7743/7743 [==============================] - 7s 952us/step - loss: 0.1225 - accuracy: 0.9560\n",
      "Epoch 105/150\n",
      "7743/7743 [==============================] - 7s 962us/step - loss: 0.1220 - accuracy: 0.9562\n",
      "Epoch 106/150\n",
      "7743/7743 [==============================] - 7s 952us/step - loss: 0.1211 - accuracy: 0.9566\n",
      "Epoch 107/150\n",
      "7743/7743 [==============================] - 7s 958us/step - loss: 0.1208 - accuracy: 0.9567\n",
      "Epoch 108/150\n",
      "7743/7743 [==============================] - 7s 952us/step - loss: 0.1208 - accuracy: 0.9569\n",
      "Epoch 109/150\n",
      "7743/7743 [==============================] - 7s 949us/step - loss: 0.1203 - accuracy: 0.9569\n",
      "Epoch 110/150\n",
      "7743/7743 [==============================] - 7s 941us/step - loss: 0.1210 - accuracy: 0.9563\n",
      "Epoch 111/150\n",
      "7743/7743 [==============================] - 7s 951us/step - loss: 0.1218 - accuracy: 0.9564\n",
      "Epoch 112/150\n",
      "7743/7743 [==============================] - 7s 955us/step - loss: 0.1203 - accuracy: 0.9568\n",
      "Epoch 113/150\n",
      "7743/7743 [==============================] - 7s 944us/step - loss: 0.1198 - accuracy: 0.9570\n",
      "Epoch 114/150\n",
      "7743/7743 [==============================] - 7s 958us/step - loss: 0.1201 - accuracy: 0.9569\n",
      "Epoch 115/150\n",
      "7743/7743 [==============================] - 7s 950us/step - loss: 0.1205 - accuracy: 0.9567\n",
      "Epoch 116/150\n",
      "7743/7743 [==============================] - 7s 950us/step - loss: 0.1192 - accuracy: 0.9572\n",
      "Epoch 117/150\n",
      "7743/7743 [==============================] - 7s 954us/step - loss: 0.1198 - accuracy: 0.9572\n",
      "Epoch 118/150\n",
      "7743/7743 [==============================] - 7s 942us/step - loss: 0.1190 - accuracy: 0.9578\n",
      "Epoch 119/150\n",
      "7743/7743 [==============================] - 7s 954us/step - loss: 0.1189 - accuracy: 0.9578\n",
      "Epoch 120/150\n",
      "7743/7743 [==============================] - 7s 951us/step - loss: 0.1189 - accuracy: 0.9575\n",
      "Epoch 121/150\n",
      "7743/7743 [==============================] - 7s 944us/step - loss: 0.1182 - accuracy: 0.9574\n",
      "Epoch 122/150\n",
      "7743/7743 [==============================] - 7s 940us/step - loss: 0.1193 - accuracy: 0.9571\n",
      "Epoch 123/150\n",
      "7743/7743 [==============================] - 7s 957us/step - loss: 0.1185 - accuracy: 0.9575\n",
      "Epoch 124/150\n",
      "7743/7743 [==============================] - 7s 941us/step - loss: 0.1174 - accuracy: 0.9581\n",
      "Epoch 125/150\n",
      "7743/7743 [==============================] - 7s 941us/step - loss: 0.1184 - accuracy: 0.9577\n",
      "Epoch 126/150\n",
      "7743/7743 [==============================] - 7s 945us/step - loss: 0.1174 - accuracy: 0.9581\n",
      "Epoch 127/150\n",
      "7743/7743 [==============================] - 7s 948us/step - loss: 0.1180 - accuracy: 0.9577\n",
      "Epoch 128/150\n",
      "7743/7743 [==============================] - 7s 942us/step - loss: 0.1176 - accuracy: 0.9574\n",
      "Epoch 129/150\n",
      "7743/7743 [==============================] - 7s 946us/step - loss: 0.1168 - accuracy: 0.9581\n",
      "Epoch 130/150\n",
      "7743/7743 [==============================] - 7s 966us/step - loss: 0.1178 - accuracy: 0.9578\n",
      "Epoch 131/150\n",
      "7743/7743 [==============================] - 7s 952us/step - loss: 0.1173 - accuracy: 0.9582\n",
      "Epoch 132/150\n",
      "7743/7743 [==============================] - 7s 951us/step - loss: 0.1168 - accuracy: 0.9584\n",
      "Epoch 133/150\n",
      "7743/7743 [==============================] - 7s 949us/step - loss: 0.1170 - accuracy: 0.9584\n",
      "Epoch 134/150\n",
      "7743/7743 [==============================] - 7s 947us/step - loss: 0.1170 - accuracy: 0.9583\n",
      "Epoch 135/150\n",
      "7743/7743 [==============================] - 7s 948us/step - loss: 0.1158 - accuracy: 0.9586\n",
      "Epoch 136/150\n",
      "7743/7743 [==============================] - 7s 947us/step - loss: 0.1165 - accuracy: 0.9585\n",
      "Epoch 137/150\n",
      "7743/7743 [==============================] - 7s 946us/step - loss: 0.1156 - accuracy: 0.9582\n",
      "Epoch 138/150\n",
      "7743/7743 [==============================] - 7s 951us/step - loss: 0.1163 - accuracy: 0.9584\n",
      "Epoch 139/150\n",
      "7743/7743 [==============================] - 7s 944us/step - loss: 0.1158 - accuracy: 0.9585\n",
      "Epoch 140/150\n",
      "7743/7743 [==============================] - 7s 957us/step - loss: 0.1153 - accuracy: 0.9584\n",
      "Epoch 141/150\n",
      "7743/7743 [==============================] - 7s 952us/step - loss: 0.1151 - accuracy: 0.9589\n",
      "Epoch 142/150\n",
      "7743/7743 [==============================] - 7s 955us/step - loss: 0.1148 - accuracy: 0.9595\n",
      "Epoch 143/150\n",
      "7743/7743 [==============================] - 7s 950us/step - loss: 0.1154 - accuracy: 0.9594\n",
      "Epoch 144/150\n",
      "7743/7743 [==============================] - 7s 950us/step - loss: 0.1150 - accuracy: 0.9588\n",
      "Epoch 145/150\n",
      "7743/7743 [==============================] - 7s 947us/step - loss: 0.1148 - accuracy: 0.9588\n",
      "Epoch 146/150\n",
      "7743/7743 [==============================] - 7s 942us/step - loss: 0.1152 - accuracy: 0.9588\n",
      "Epoch 147/150\n",
      "7743/7743 [==============================] - 7s 949us/step - loss: 0.1140 - accuracy: 0.9596\n",
      "Epoch 148/150\n",
      "7743/7743 [==============================] - 7s 952us/step - loss: 0.1144 - accuracy: 0.9594\n",
      "Epoch 149/150\n",
      "7743/7743 [==============================] - 7s 954us/step - loss: 0.1144 - accuracy: 0.9592\n",
      "Epoch 150/150\n",
      "7743/7743 [==============================] - 8s 972us/step - loss: 0.1141 - accuracy: 0.9590\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "epochs_hist = model.fit(X_train_s,y_train_s,epochs=150,batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dff1df9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Loss and Accuracy plot')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred=model.predict(X_test)\n",
    "\n",
    "y_pred = (y_pred>0.5)\n",
    "\n",
    "plt.plot(epochs_hist.history['loss'])\n",
    "plt.plot(epochs_hist.history['accuracy'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('percentage')\n",
    "plt.legend(['loss','accuracy'])\n",
    "plt.title('Loss and Accuracy plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f2f20e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95     33147\n",
      "           1       0.26      0.41      0.32      2055\n",
      "\n",
      "    accuracy                           0.90     35202\n",
      "   macro avg       0.61      0.67      0.63     35202\n",
      "weighted avg       0.92      0.90      0.91     35202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22a3750d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_res = y_train_s.reshape(-1, 1)\n",
    "# data_res = np.concatenate((X_train_s, y_train_s), axis = 0)\n",
    "# data_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d378f9c0",
   "metadata": {},
   "source": [
    "## RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec263c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RFECV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "      estimator=RandomForestClassifier(random_state=42), scoring='accuracy')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import cross_validate, RepeatedStratifiedKFold, learning_curve, cross_val_score, RandomizedSearchCV, train_test_split, StratifiedKFold\n",
    "\n",
    "rfecv = RFECV(estimator=rfc, cv=StratifiedKFold(5, random_state=42, shuffle=True), scoring=\"accuracy\")\n",
    "rfecv.fit(X_train_s, y_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e46b77b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d4d9634",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rfe = X_train_s.iloc[:, rfecv.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "630f8db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"X\" dimension: (154856, 104)\n",
      "\"X\" column list: ['disrict', 'client_catg', 'region', 'region_group', 'coop_time', 'is_weekday_mean', 'transactions_count', 'tarif_type_mean', 'tarif_type_std', 'tarif_type_min', 'tarif_type_max', 'counter_number_mean', 'counter_number_std', 'counter_number_min', 'counter_number_max', 'counter_statue_mean', 'counter_statue_std', 'counter_statue_min', 'counter_statue_max', 'counter_code_mean', 'counter_code_std', 'counter_code_min', 'counter_code_max', 'reading_remarque_mean', 'reading_remarque_std', 'reading_remarque_min', 'reading_remarque_max', 'consommation_level_1_mean', 'consommation_level_1_std', 'consommation_level_1_min', 'consommation_level_1_max', 'consommation_level_2_mean', 'consommation_level_2_std', 'consommation_level_2_min', 'consommation_level_2_max', 'consommation_level_3_mean', 'consommation_level_3_std', 'consommation_level_3_min', 'consommation_level_3_max', 'consommation_level_4_mean', 'consommation_level_4_std', 'consommation_level_4_min', 'consommation_level_4_max', 'old_index_mean', 'old_index_std', 'old_index_min', 'old_index_max', 'new_index_mean', 'new_index_std', 'new_index_min', 'new_index_max', 'months_number_mean', 'months_number_std', 'months_number_min', 'months_number_max', 'counter_type_mean', 'counter_type_std', 'counter_type_min', 'counter_type_max', 'invoice_month_mean', 'invoice_month_std', 'invoice_month_min', 'invoice_month_max', 'invoice_year_mean', 'invoice_year_std', 'invoice_year_min', 'invoice_year_max', 'delta_index_mean', 'delta_index_std', 'delta_index_min', 'delta_index_max', 'delta_time_mean', 'delta_time_std', 'delta_time_min', 'delta_time_max', 'invoice_per_cooperation', 'tarif_type_range', 'tarif_type_max_mean', 'counter_number_range', 'counter_number_max_mean', 'counter_statue_range', 'counter_code_range', 'counter_code_max_mean', 'reading_remarque_range', 'reading_remarque_max_mean', 'consommation_level_1_range', 'consommation_level_1_max_mean', 'consommation_level_2_range', 'consommation_level_3_range', 'consommation_level_4_range', 'old_index_range', 'old_index_max_mean', 'new_index_range', 'new_index_max_mean', 'months_number_range', 'months_number_max_mean', 'counter_type_range', 'counter_type_max_mean', 'invoice_month_range', 'invoice_month_max_mean', 'invoice_year_range', 'invoice_year_max_mean', 'delta_index_range', 'delta_index_max_mean']\n",
      "\"X_rfe\" dimension: (154856, 95)\n",
      "\"X_rfe\" column list: ['disrict', 'region', 'region_group', 'coop_time', 'is_weekday_mean', 'transactions_count', 'tarif_type_mean', 'tarif_type_std', 'tarif_type_min', 'tarif_type_max', 'counter_number_mean', 'counter_number_std', 'counter_number_min', 'counter_number_max', 'counter_statue_mean', 'counter_statue_std', 'counter_statue_max', 'counter_code_mean', 'counter_code_std', 'counter_code_min', 'counter_code_max', 'reading_remarque_mean', 'reading_remarque_std', 'consommation_level_1_mean', 'consommation_level_1_std', 'consommation_level_1_min', 'consommation_level_1_max', 'consommation_level_2_mean', 'consommation_level_2_std', 'consommation_level_2_max', 'consommation_level_3_mean', 'consommation_level_3_std', 'consommation_level_3_max', 'consommation_level_4_mean', 'consommation_level_4_std', 'consommation_level_4_max', 'old_index_mean', 'old_index_std', 'old_index_min', 'old_index_max', 'new_index_mean', 'new_index_std', 'new_index_min', 'new_index_max', 'months_number_mean', 'months_number_std', 'months_number_min', 'months_number_max', 'counter_type_mean', 'counter_type_std', 'counter_type_min', 'invoice_month_mean', 'invoice_month_std', 'invoice_month_min', 'invoice_month_max', 'invoice_year_mean', 'invoice_year_std', 'invoice_year_min', 'invoice_year_max', 'delta_index_mean', 'delta_index_std', 'delta_index_min', 'delta_index_max', 'delta_time_mean', 'delta_time_std', 'delta_time_min', 'delta_time_max', 'invoice_per_cooperation', 'tarif_type_range', 'tarif_type_max_mean', 'counter_number_range', 'counter_number_max_mean', 'counter_statue_range', 'counter_code_range', 'counter_code_max_mean', 'reading_remarque_range', 'reading_remarque_max_mean', 'consommation_level_1_range', 'consommation_level_1_max_mean', 'consommation_level_2_range', 'consommation_level_3_range', 'consommation_level_4_range', 'old_index_range', 'old_index_max_mean', 'new_index_range', 'new_index_max_mean', 'months_number_range', 'months_number_max_mean', 'counter_type_max_mean', 'invoice_month_range', 'invoice_month_max_mean', 'invoice_year_range', 'invoice_year_max_mean', 'delta_index_range', 'delta_index_max_mean']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\\"X\\\" dimension: {}\".format(X_train_s.shape))\n",
    "print(\"\\\"X\\\" column list:\", X_train_s.columns.tolist())\n",
    "print(\"\\\"X_rfe\\\" dimension: {}\".format(X_rfe.shape))\n",
    "print(\"\\\"X_rfe\\\" column list:\", X_rfe.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c15e268e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 108399\n",
      "Test size: 46457\n"
     ]
    }
   ],
   "source": [
    "X_rfe_train, X_rfe_test, y_train, y_test = train_test_split(X_rfe, y_train_s, \n",
    "                                                                             test_size=0.3, \n",
    "                                                                             stratify=y_train_s,\n",
    "                                                                             random_state=42)\n",
    "print(\"Train size: {}\".format(len(y_train_r)))\n",
    "print(\"Test size: {}\".format(len(y_test_r)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "63028d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helping function\n",
    "\n",
    "def conf(algo_name,X_test, y_test):\n",
    "    y_pred = algo_name.predict(X_test)\n",
    "    forest_cm = metrics.confusion_matrix(y_pred, y_test, [1,0])\n",
    "    sns.heatmap(forest_cm, annot=True, fmt='.2f',xticklabels = [\"1\", \"0\"] , yticklabels = [\"1\", \"0\"] )\n",
    "    plt.ylabel('True class')\n",
    "    plt.xlabel('Predicted class')\n",
    "    plt.title(str(algo_name)[0:str(algo_name).find('(')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f022253a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test = {}\n",
    "results_train = {}\n",
    "list_algos=[]\n",
    "\n",
    "def predict(algo_name,X_train,y_train,X_test,y_test, atype='',verbose=0):\n",
    "    algo_name.fit(X_train, y_train)\n",
    "    Y_pred = algo_name.predict(X_test)\n",
    "    acc_train = round(algo_name.score(X_train, y_train) * 100, 2)\n",
    "    acc_val = round(algo_name.score(X_test, y_test) * 100, 2)\n",
    "    \n",
    "    results_test[str(algo_name)[0:str(algo_name).find('(')]+'_'+str(atype)] = acc_val\n",
    "    results_train[str(algo_name)[0:str(algo_name).find('(')]+'_'+str(atype)] = acc_train\n",
    "    list_algos.append(str(algo_name)[0:str(algo_name).find('(')])\n",
    "    if verbose ==0:\n",
    "        print(\"Training Accuracy: \" + str(acc_train))\n",
    "        print(\"Testing  Accuracy: \"+ str(acc_val))\n",
    "    else:\n",
    "        return Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ca6f6ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 99.36\n",
      "Testing  Accuracy: 95.87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96     23229\n",
      "           1       0.94      0.98      0.96     23228\n",
      "\n",
      "    accuracy                           0.96     46457\n",
      "   macro avg       0.96      0.96      0.96     46457\n",
      "weighted avg       0.96      0.96      0.96     46457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "\n",
    "knneig = KNeighborsClassifier(n_neighbors=2)\n",
    "knneig.fit(X_rfe_train, y_train)\n",
    "predict(knneig,X_rfe_train,y_train,X_rfe_test,y_test)\n",
    "print(classification_report(y_test, knneig.predict(X_rfe_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "62252b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 100.0\n",
      "Testing  Accuracy: 97.06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     23229\n",
      "           1       0.98      0.96      0.97     23228\n",
      "\n",
      "    accuracy                           0.97     46457\n",
      "   macro avg       0.97      0.97      0.97     46457\n",
      "weighted avg       0.97      0.97      0.97     46457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#RF\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=250, random_state = 42)\n",
    "predict(rf,X_rfe_train,y_train,X_rfe_test,y_test)\n",
    "print(classification_report(y_test, rf.predict(X_rfe_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e376ebc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moinu\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass labels=[1, 0] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf(rf,X_rfe_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "49a5aa61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 80.71\n",
      "Testing  Accuracy: 80.45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.81     23229\n",
      "           1       0.84      0.75      0.79     23228\n",
      "\n",
      "    accuracy                           0.80     46457\n",
      "   macro avg       0.81      0.80      0.80     46457\n",
      "weighted avg       0.81      0.80      0.80     46457\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moinu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#LR\n",
    "\n",
    "lr = LogisticRegression()\n",
    "predict(lr,X_rfe_train,y_train,X_rfe_test,y_test)\n",
    "print(classification_report(y_test, lr.predict(X_rfe_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "523f2ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 93.35\n",
      "Testing  Accuracy: 93.22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93     23229\n",
      "           1       0.95      0.91      0.93     23228\n",
      "\n",
      "    accuracy                           0.93     46457\n",
      "   macro avg       0.93      0.93      0.93     46457\n",
      "weighted avg       0.93      0.93      0.93     46457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# GBC\n",
    "\n",
    "gbc = GradientBoostingClassifier()\n",
    "predict(gbc,X_rfe_train,y_train,X_rfe_test,y_test)\n",
    "print(classification_report(y_test, gbc.predict(X_rfe_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e6a38d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 90.14\n",
      "Testing  Accuracy: 90.21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.90     23229\n",
      "           1       0.91      0.89      0.90     23228\n",
      "\n",
      "    accuracy                           0.90     46457\n",
      "   macro avg       0.90      0.90      0.90     46457\n",
      "weighted avg       0.90      0.90      0.90     46457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ADA\n",
    "\n",
    "ada = AdaBoostClassifier()\n",
    "predict(ada,X_rfe_train,y_train,X_rfe_test,y_test)\n",
    "print(classification_report(y_test, ada.predict(X_rfe_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a698014",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moinu\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:52:48] WARNING: ..\\src\\learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moinu\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\moinu\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 97.98\n",
      "Testing  Accuracy: 96.96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     23229\n",
      "           1       0.98      0.96      0.97     23228\n",
      "\n",
      "    accuracy                           0.97     46457\n",
      "   macro avg       0.97      0.97      0.97     46457\n",
      "weighted avg       0.97      0.97      0.97     46457\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moinu\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#xgb\n",
    "\n",
    "xg = xgb.XGBClassifier()\n",
    "predict(xg,X_rfe_train,y_train,X_rfe_test,y_test)\n",
    "print(classification_report(y_test, xg.predict(X_rfe_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9f2b75f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moinu\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 90.9\n",
      "Testing  Accuracy: 90.18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.90     23229\n",
      "           1       0.89      0.92      0.90     23228\n",
      "\n",
      "    accuracy                           0.90     46457\n",
      "   macro avg       0.90      0.90      0.90     46457\n",
      "weighted avg       0.90      0.90      0.90     46457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#MLP\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(random_state=1)\n",
    "predict(mlp,X_rfe_train,y_train,X_rfe_test,y_test)\n",
    "print(classification_report(y_test, mlp.predict(X_rfe_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7509ba20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "model= tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(units=64,activation='relu',input_shape= (95,)))\n",
    "model.add(tf.keras.layers.Dense(units=128,activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(units=1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c099d78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                6144      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 14,593\n",
      "Trainable params: 14,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fc053e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "5420/5420 [==============================] - 5s 944us/step - loss: 0.3896 - accuracy: 0.8122\n",
      "Epoch 2/150\n",
      "5420/5420 [==============================] - 5s 915us/step - loss: 0.3571 - accuracy: 0.8321\n",
      "Epoch 3/150\n",
      "5420/5420 [==============================] - 5s 930us/step - loss: 0.3421 - accuracy: 0.8400\n",
      "Epoch 4/150\n",
      "5420/5420 [==============================] - 5s 917us/step - loss: 0.3316 - accuracy: 0.8473\n",
      "Epoch 5/150\n",
      "5420/5420 [==============================] - 5s 916us/step - loss: 0.3241 - accuracy: 0.8500\n",
      "Epoch 6/150\n",
      "5420/5420 [==============================] - 5s 913us/step - loss: 0.3180 - accuracy: 0.8539\n",
      "Epoch 7/150\n",
      "5420/5420 [==============================] - 5s 948us/step - loss: 0.3095 - accuracy: 0.8592\n",
      "Epoch 8/150\n",
      "5420/5420 [==============================] - 5s 944us/step - loss: 0.3041 - accuracy: 0.8613\n",
      "Epoch 9/150\n",
      "5420/5420 [==============================] - 5s 949us/step - loss: 0.2971 - accuracy: 0.8665\n",
      "Epoch 10/150\n",
      "5420/5420 [==============================] - 5s 949us/step - loss: 0.2935 - accuracy: 0.8699\n",
      "Epoch 11/150\n",
      "5420/5420 [==============================] - 5s 957us/step - loss: 0.2891 - accuracy: 0.8719\n",
      "Epoch 12/150\n",
      "5420/5420 [==============================] - 5s 937us/step - loss: 0.2833 - accuracy: 0.8755\n",
      "Epoch 13/150\n",
      "5420/5420 [==============================] - 5s 959us/step - loss: 0.2798 - accuracy: 0.8766\n",
      "Epoch 14/150\n",
      "5420/5420 [==============================] - 5s 960us/step - loss: 0.2758 - accuracy: 0.8786\n",
      "Epoch 15/150\n",
      "5420/5420 [==============================] - 5s 962us/step - loss: 0.2711 - accuracy: 0.8825\n",
      "Epoch 16/150\n",
      "5420/5420 [==============================] - 5s 944us/step - loss: 0.2682 - accuracy: 0.8831\n",
      "Epoch 17/150\n",
      "5420/5420 [==============================] - 5s 969us/step - loss: 0.2644 - accuracy: 0.8852\n",
      "Epoch 18/150\n",
      "5420/5420 [==============================] - 5s 972us/step - loss: 0.2605 - accuracy: 0.8882\n",
      "Epoch 19/150\n",
      "5420/5420 [==============================] - 5s 954us/step - loss: 0.2575 - accuracy: 0.8895\n",
      "Epoch 20/150\n",
      "5420/5420 [==============================] - 5s 958us/step - loss: 0.2546 - accuracy: 0.8915\n",
      "Epoch 21/150\n",
      "5420/5420 [==============================] - 5s 965us/step - loss: 0.2519 - accuracy: 0.8929\n",
      "Epoch 22/150\n",
      "5420/5420 [==============================] - 5s 963us/step - loss: 0.2493 - accuracy: 0.8943\n",
      "Epoch 23/150\n",
      "5420/5420 [==============================] - 5s 969us/step - loss: 0.2462 - accuracy: 0.8962\n",
      "Epoch 24/150\n",
      "5420/5420 [==============================] - 5s 949us/step - loss: 0.2448 - accuracy: 0.8965\n",
      "Epoch 25/150\n",
      "5420/5420 [==============================] - 5s 946us/step - loss: 0.2412 - accuracy: 0.8986\n",
      "Epoch 26/150\n",
      "5420/5420 [==============================] - 5s 954us/step - loss: 0.2381 - accuracy: 0.9005\n",
      "Epoch 27/150\n",
      "5420/5420 [==============================] - 5s 984us/step - loss: 0.2364 - accuracy: 0.9017\n",
      "Epoch 28/150\n",
      "5420/5420 [==============================] - 5s 946us/step - loss: 0.2342 - accuracy: 0.9025\n",
      "Epoch 29/150\n",
      "5420/5420 [==============================] - 5s 952us/step - loss: 0.2321 - accuracy: 0.9045\n",
      "Epoch 30/150\n",
      "5420/5420 [==============================] - 5s 954us/step - loss: 0.2307 - accuracy: 0.9043\n",
      "Epoch 31/150\n",
      "5420/5420 [==============================] - 5s 953us/step - loss: 0.2280 - accuracy: 0.9047\n",
      "Epoch 32/150\n",
      "5420/5420 [==============================] - 5s 959us/step - loss: 0.2265 - accuracy: 0.9064\n",
      "Epoch 33/150\n",
      "5420/5420 [==============================] - 5s 970us/step - loss: 0.2237 - accuracy: 0.9081\n",
      "Epoch 34/150\n",
      "5420/5420 [==============================] - 5s 964us/step - loss: 0.2228 - accuracy: 0.9082\n",
      "Epoch 35/150\n",
      "5420/5420 [==============================] - 5s 942us/step - loss: 0.2204 - accuracy: 0.9102\n",
      "Epoch 36/150\n",
      "5420/5420 [==============================] - 5s 952us/step - loss: 0.2185 - accuracy: 0.9112\n",
      "Epoch 37/150\n",
      "5420/5420 [==============================] - 5s 948us/step - loss: 0.2163 - accuracy: 0.9120\n",
      "Epoch 38/150\n",
      "5420/5420 [==============================] - 5s 950us/step - loss: 0.2142 - accuracy: 0.9141\n",
      "Epoch 39/150\n",
      "5420/5420 [==============================] - 5s 960us/step - loss: 0.2124 - accuracy: 0.9139\n",
      "Epoch 40/150\n",
      "5420/5420 [==============================] - 5s 954us/step - loss: 0.2115 - accuracy: 0.9150\n",
      "Epoch 41/150\n",
      "5420/5420 [==============================] - 5s 949us/step - loss: 0.2095 - accuracy: 0.9153\n",
      "Epoch 42/150\n",
      "5420/5420 [==============================] - 5s 950us/step - loss: 0.2074 - accuracy: 0.9169\n",
      "Epoch 43/150\n",
      "5420/5420 [==============================] - 5s 954us/step - loss: 0.2055 - accuracy: 0.9176\n",
      "Epoch 44/150\n",
      "5420/5420 [==============================] - 5s 956us/step - loss: 0.2041 - accuracy: 0.9186\n",
      "Epoch 45/150\n",
      "5420/5420 [==============================] - 5s 963us/step - loss: 0.2016 - accuracy: 0.9202\n",
      "Epoch 46/150\n",
      "5420/5420 [==============================] - 5s 951us/step - loss: 0.2005 - accuracy: 0.9207\n",
      "Epoch 47/150\n",
      "5420/5420 [==============================] - 5s 965us/step - loss: 0.1998 - accuracy: 0.9213\n",
      "Epoch 48/150\n",
      "5420/5420 [==============================] - 5s 962us/step - loss: 0.1984 - accuracy: 0.9221\n",
      "Epoch 49/150\n",
      "5420/5420 [==============================] - 5s 957us/step - loss: 0.1964 - accuracy: 0.9227\n",
      "Epoch 50/150\n",
      "5420/5420 [==============================] - 5s 963us/step - loss: 0.1949 - accuracy: 0.9226\n",
      "Epoch 51/150\n",
      "5420/5420 [==============================] - 5s 961us/step - loss: 0.1939 - accuracy: 0.9236\n",
      "Epoch 52/150\n",
      "5420/5420 [==============================] - 5s 963us/step - loss: 0.1921 - accuracy: 0.9255\n",
      "Epoch 53/150\n",
      "5420/5420 [==============================] - 5s 976us/step - loss: 0.1917 - accuracy: 0.9257\n",
      "Epoch 54/150\n",
      "5420/5420 [==============================] - 5s 953us/step - loss: 0.1906 - accuracy: 0.9257\n",
      "Epoch 55/150\n",
      "5420/5420 [==============================] - 5s 952us/step - loss: 0.1890 - accuracy: 0.9260\n",
      "Epoch 56/150\n",
      "5420/5420 [==============================] - 5s 950us/step - loss: 0.1878 - accuracy: 0.9270\n",
      "Epoch 57/150\n",
      "5420/5420 [==============================] - 5s 952us/step - loss: 0.1863 - accuracy: 0.9277\n",
      "Epoch 58/150\n",
      "5420/5420 [==============================] - 5s 964us/step - loss: 0.1859 - accuracy: 0.9280\n",
      "Epoch 59/150\n",
      "5420/5420 [==============================] - 5s 950us/step - loss: 0.1847 - accuracy: 0.9286\n",
      "Epoch 60/150\n",
      "5420/5420 [==============================] - 5s 951us/step - loss: 0.1840 - accuracy: 0.9289\n",
      "Epoch 61/150\n",
      "5420/5420 [==============================] - 5s 959us/step - loss: 0.1816 - accuracy: 0.9293\n",
      "Epoch 62/150\n",
      "5420/5420 [==============================] - 5s 972us/step - loss: 0.1817 - accuracy: 0.9299\n",
      "Epoch 63/150\n",
      "5420/5420 [==============================] - 5s 946us/step - loss: 0.1804 - accuracy: 0.9295\n",
      "Epoch 64/150\n",
      "5420/5420 [==============================] - 5s 971us/step - loss: 0.1792 - accuracy: 0.9316\n",
      "Epoch 65/150\n",
      "5420/5420 [==============================] - 5s 965us/step - loss: 0.1781 - accuracy: 0.9312\n",
      "Epoch 66/150\n",
      "5420/5420 [==============================] - 5s 957us/step - loss: 0.1772 - accuracy: 0.9320\n",
      "Epoch 67/150\n",
      "5420/5420 [==============================] - 5s 966us/step - loss: 0.1766 - accuracy: 0.9323\n",
      "Epoch 68/150\n",
      "5420/5420 [==============================] - 5s 976us/step - loss: 0.1756 - accuracy: 0.9323\n",
      "Epoch 69/150\n",
      "5420/5420 [==============================] - 5s 969us/step - loss: 0.1752 - accuracy: 0.9328\n",
      "Epoch 70/150\n",
      "5420/5420 [==============================] - 5s 964us/step - loss: 0.1739 - accuracy: 0.9330\n",
      "Epoch 71/150\n",
      "5420/5420 [==============================] - 5s 962us/step - loss: 0.1726 - accuracy: 0.9339\n",
      "Epoch 72/150\n",
      "5420/5420 [==============================] - 5s 959us/step - loss: 0.1720 - accuracy: 0.9337\n",
      "Epoch 73/150\n",
      "5420/5420 [==============================] - 5s 965us/step - loss: 0.1719 - accuracy: 0.9340\n",
      "Epoch 74/150\n",
      "5420/5420 [==============================] - 5s 988us/step - loss: 0.1711 - accuracy: 0.9347\n",
      "Epoch 75/150\n",
      "5420/5420 [==============================] - 5s 963us/step - loss: 0.1691 - accuracy: 0.9360\n",
      "Epoch 76/150\n",
      "5420/5420 [==============================] - 5s 968us/step - loss: 0.1682 - accuracy: 0.9361\n",
      "Epoch 77/150\n",
      "5420/5420 [==============================] - 5s 973us/step - loss: 0.1687 - accuracy: 0.9357\n",
      "Epoch 78/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5420/5420 [==============================] - 5s 951us/step - loss: 0.1673 - accuracy: 0.9370\n",
      "Epoch 79/150\n",
      "5420/5420 [==============================] - 5s 954us/step - loss: 0.1662 - accuracy: 0.9364\n",
      "Epoch 80/150\n",
      "5420/5420 [==============================] - 5s 955us/step - loss: 0.1654 - accuracy: 0.9372\n",
      "Epoch 81/150\n",
      "5420/5420 [==============================] - 5s 951us/step - loss: 0.1658 - accuracy: 0.9372\n",
      "Epoch 82/150\n",
      "5420/5420 [==============================] - 5s 945us/step - loss: 0.1652 - accuracy: 0.9372\n",
      "Epoch 83/150\n",
      "5420/5420 [==============================] - 5s 940us/step - loss: 0.1639 - accuracy: 0.9376\n",
      "Epoch 84/150\n",
      "5420/5420 [==============================] - 5s 952us/step - loss: 0.1629 - accuracy: 0.9380\n",
      "Epoch 85/150\n",
      "5420/5420 [==============================] - 5s 953us/step - loss: 0.1626 - accuracy: 0.9379\n",
      "Epoch 86/150\n",
      "5420/5420 [==============================] - 5s 948us/step - loss: 0.1628 - accuracy: 0.9381\n",
      "Epoch 87/150\n",
      "5420/5420 [==============================] - 5s 951us/step - loss: 0.1614 - accuracy: 0.9384\n",
      "Epoch 88/150\n",
      "5420/5420 [==============================] - 5s 996us/step - loss: 0.1607 - accuracy: 0.9397\n",
      "Epoch 89/150\n",
      "5420/5420 [==============================] - 5s 972us/step - loss: 0.1609 - accuracy: 0.9392\n",
      "Epoch 90/150\n",
      "5420/5420 [==============================] - 5s 981us/step - loss: 0.1599 - accuracy: 0.9398\n",
      "Epoch 91/150\n",
      "5420/5420 [==============================] - 5s 971us/step - loss: 0.1594 - accuracy: 0.9391\n",
      "Epoch 92/150\n",
      "5420/5420 [==============================] - 5s 977us/step - loss: 0.1584 - accuracy: 0.9410\n",
      "Epoch 93/150\n",
      "5420/5420 [==============================] - 5s 962us/step - loss: 0.1583 - accuracy: 0.9404\n",
      "Epoch 94/150\n",
      "5420/5420 [==============================] - 5s 955us/step - loss: 0.1569 - accuracy: 0.9415\n",
      "Epoch 95/150\n",
      "5420/5420 [==============================] - 5s 983us/step - loss: 0.1577 - accuracy: 0.9412\n",
      "Epoch 96/150\n",
      "5420/5420 [==============================] - 5s 973us/step - loss: 0.1561 - accuracy: 0.9411\n",
      "Epoch 97/150\n",
      "5420/5420 [==============================] - 5s 988us/step - loss: 0.1562 - accuracy: 0.9411\n",
      "Epoch 98/150\n",
      "5420/5420 [==============================] - 5s 984us/step - loss: 0.1549 - accuracy: 0.9418\n",
      "Epoch 99/150\n",
      "5420/5420 [==============================] - 5s 1ms/step - loss: 0.1546 - accuracy: 0.9418\n",
      "Epoch 100/150\n",
      "5420/5420 [==============================] - 5s 975us/step - loss: 0.1535 - accuracy: 0.9422\n",
      "Epoch 101/150\n",
      "5420/5420 [==============================] - 5s 991us/step - loss: 0.1537 - accuracy: 0.9419\n",
      "Epoch 102/150\n",
      "5420/5420 [==============================] - 6s 1ms/step - loss: 0.1542 - accuracy: 0.9418\n",
      "Epoch 103/150\n",
      "5420/5420 [==============================] - 6s 1ms/step - loss: 0.1526 - accuracy: 0.9423\n",
      "Epoch 104/150\n",
      "5420/5420 [==============================] - 6s 1ms/step - loss: 0.1523 - accuracy: 0.9426\n",
      "Epoch 105/150\n",
      "5420/5420 [==============================] - 5s 979us/step - loss: 0.1515 - accuracy: 0.9434\n",
      "Epoch 106/150\n",
      "5420/5420 [==============================] - 6s 1ms/step - loss: 0.1514 - accuracy: 0.9432\n",
      "Epoch 107/150\n",
      "5420/5420 [==============================] - 6s 1ms/step - loss: 0.1512 - accuracy: 0.9436\n",
      "Epoch 108/150\n",
      "5420/5420 [==============================] - 6s 1ms/step - loss: 0.1509 - accuracy: 0.9434\n",
      "Epoch 109/150\n",
      "5420/5420 [==============================] - 6s 1ms/step - loss: 0.1503 - accuracy: 0.9436\n",
      "Epoch 110/150\n",
      "5420/5420 [==============================] - 5s 938us/step - loss: 0.1497 - accuracy: 0.9441\n",
      "Epoch 111/150\n",
      "5420/5420 [==============================] - 5s 958us/step - loss: 0.1497 - accuracy: 0.9439\n",
      "Epoch 112/150\n",
      "5420/5420 [==============================] - 5s 989us/step - loss: 0.1486 - accuracy: 0.9438\n",
      "Epoch 113/150\n",
      "5420/5420 [==============================] - 5s 956us/step - loss: 0.1472 - accuracy: 0.9450\n",
      "Epoch 114/150\n",
      "5420/5420 [==============================] - 5s 988us/step - loss: 0.1477 - accuracy: 0.9441\n",
      "Epoch 115/150\n",
      "5420/5420 [==============================] - 5s 938us/step - loss: 0.1473 - accuracy: 0.9450\n",
      "Epoch 116/150\n",
      "5420/5420 [==============================] - 5s 957us/step - loss: 0.1470 - accuracy: 0.9446\n",
      "Epoch 117/150\n",
      "5420/5420 [==============================] - 5s 1ms/step - loss: 0.1466 - accuracy: 0.9449\n",
      "Epoch 118/150\n",
      "5420/5420 [==============================] - 5s 1ms/step - loss: 0.1451 - accuracy: 0.9456\n",
      "Epoch 119/150\n",
      "5420/5420 [==============================] - 5s 1ms/step - loss: 0.1464 - accuracy: 0.9452\n",
      "Epoch 120/150\n",
      "5420/5420 [==============================] - 5s 975us/step - loss: 0.1446 - accuracy: 0.9459\n",
      "Epoch 121/150\n",
      "5420/5420 [==============================] - 6s 1ms/step - loss: 0.1444 - accuracy: 0.9462\n",
      "Epoch 122/150\n",
      "5420/5420 [==============================] - 5s 990us/step - loss: 0.1448 - accuracy: 0.9458\n",
      "Epoch 123/150\n",
      "5420/5420 [==============================] - 5s 1ms/step - loss: 0.1445 - accuracy: 0.9461\n",
      "Epoch 124/150\n",
      "5420/5420 [==============================] - 6s 1ms/step - loss: 0.1431 - accuracy: 0.9467\n",
      "Epoch 125/150\n",
      "5420/5420 [==============================] - 6s 1ms/step - loss: 0.1429 - accuracy: 0.9464\n",
      "Epoch 126/150\n",
      "5420/5420 [==============================] - 6s 1ms/step - loss: 0.1423 - accuracy: 0.9467\n",
      "Epoch 127/150\n",
      "5420/5420 [==============================] - 5s 1ms/step - loss: 0.1423 - accuracy: 0.9470\n",
      "Epoch 128/150\n",
      "5420/5420 [==============================] - 5s 981us/step - loss: 0.1411 - accuracy: 0.9473\n",
      "Epoch 129/150\n",
      "5420/5420 [==============================] - 5s 968us/step - loss: 0.1419 - accuracy: 0.9471\n",
      "Epoch 130/150\n",
      "5420/5420 [==============================] - 6s 1ms/step - loss: 0.1413 - accuracy: 0.9475\n",
      "Epoch 131/150\n",
      "5420/5420 [==============================] - 6s 1ms/step - loss: 0.1403 - accuracy: 0.9480\n",
      "Epoch 132/150\n",
      "5420/5420 [==============================] - 6s 1ms/step - loss: 0.1399 - accuracy: 0.9473\n",
      "Epoch 133/150\n",
      "5420/5420 [==============================] - 5s 1ms/step - loss: 0.1397 - accuracy: 0.9481\n",
      "Epoch 134/150\n",
      "5420/5420 [==============================] - 6s 1ms/step - loss: 0.1396 - accuracy: 0.9477\n",
      "Epoch 135/150\n",
      "5420/5420 [==============================] - 5s 974us/step - loss: 0.1383 - accuracy: 0.9492\n",
      "Epoch 136/150\n",
      "5420/5420 [==============================] - 5s 970us/step - loss: 0.1389 - accuracy: 0.9485\n",
      "Epoch 137/150\n",
      "5420/5420 [==============================] - 5s 949us/step - loss: 0.1386 - accuracy: 0.9485\n",
      "Epoch 138/150\n",
      "5420/5420 [==============================] - 5s 972us/step - loss: 0.1379 - accuracy: 0.9489\n",
      "Epoch 139/150\n",
      "5420/5420 [==============================] - 5s 950us/step - loss: 0.1377 - accuracy: 0.9487\n",
      "Epoch 140/150\n",
      "5420/5420 [==============================] - 5s 970us/step - loss: 0.1382 - accuracy: 0.9484\n",
      "Epoch 141/150\n",
      "5420/5420 [==============================] - 5s 971us/step - loss: 0.1394 - accuracy: 0.9474\n",
      "Epoch 142/150\n",
      "5420/5420 [==============================] - 5s 979us/step - loss: 0.1370 - accuracy: 0.9491\n",
      "Epoch 143/150\n",
      "5420/5420 [==============================] - 5s 965us/step - loss: 0.1364 - accuracy: 0.9490\n",
      "Epoch 144/150\n",
      "5420/5420 [==============================] - 5s 935us/step - loss: 0.1366 - accuracy: 0.9494\n",
      "Epoch 145/150\n",
      "5420/5420 [==============================] - 5s 945us/step - loss: 0.1359 - accuracy: 0.9496\n",
      "Epoch 146/150\n",
      "5420/5420 [==============================] - 5s 970us/step - loss: 0.1365 - accuracy: 0.9493\n",
      "Epoch 147/150\n",
      "5420/5420 [==============================] - 5s 963us/step - loss: 0.1360 - accuracy: 0.9494\n",
      "Epoch 148/150\n",
      "5420/5420 [==============================] - 5s 963us/step - loss: 0.1351 - accuracy: 0.9499\n",
      "Epoch 149/150\n",
      "5420/5420 [==============================] - 5s 947us/step - loss: 0.1350 - accuracy: 0.9501\n",
      "Epoch 150/150\n",
      "5420/5420 [==============================] - 5s 951us/step - loss: 0.1351 - accuracy: 0.9501\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "epochs_hist = model.fit(X_rfe_train,y_train,epochs=150,batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f710261b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Loss and Accuracy plot')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred=model.predict(X_rfe_test)\n",
    "\n",
    "y_pred = (y_pred>0.5)\n",
    "\n",
    "plt.plot(epochs_hist.history['loss'])\n",
    "plt.plot(epochs_hist.history['accuracy'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('percentage')\n",
    "plt.legend(['loss','accuracy'])\n",
    "plt.title('Loss and Accuracy plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d59cf031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93     23229\n",
      "           1       0.92      0.94      0.93     23228\n",
      "\n",
      "    accuracy                           0.93     46457\n",
      "   macro avg       0.93      0.93      0.93     46457\n",
      "weighted avg       0.93      0.93      0.93     46457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ca4d94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
